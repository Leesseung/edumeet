# main.py
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import os, re, glob, wave, traceback, subprocess, requests, time, json, shutil
from dotenv import load_dotenv
from openai import OpenAI
from fpdf import FPDF
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"],
)

HERE = os.path.dirname(os.path.abspath(__file__))
BASE_AUDIO_DIR = os.environ.get(
    "AUDIO_BASE_DIR",
    os.path.normpath(os.path.join(HERE, "..", "backend", "audio"))
)
MERGE_OUT_DIR = os.environ.get(
    "MERGE_OUT_DIR",
    os.path.normpath(os.path.join(HERE, "..", "FastAPIProject"))
)
os.makedirs(MERGE_OUT_DIR, exist_ok=True)

def _numeric_key(path: str) -> int:
    """audio_12.wav -> 12 ì •ë ¬í‚¤"""
    name = os.path.basename(path)
    m = re.search(r"(\d+)", name)
    return int(m.group(1)) if m else 0

def _peek_header(path: str, n=16) -> bytes:
    try:
        with open(path, "rb") as f:
            return f.read(n)
    except Exception:
        return b""


def _is_riff(path: str) -> bool:
    try:
        with open(path, "rb") as f:
            return f.read(4) == b"RIFF"
    except Exception:
        return False


def ensure_wav(file_path: str) -> str:
    # ì´ë¯¸ WAV(RIFF)ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    try:
        with open(file_path, 'rb') as f:
            if f.read(4) == b'RIFF':
                return file_path
    except Exception:
        pass

    # ë³€í™˜ ê²½ë¡œ
    base, _ = os.path.splitext(file_path)
    wav_path = base + ".conv.wav"

    # ffmpeg ë³€í™˜ (16kHz, mono, PCM 16-bit)
    cmd = ["ffmpeg", "-y", "-i", file_path, "-ar", "16000", "-ac", "1", "-acodec", "pcm_s16le", wav_path]
    subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

    # ë³€í™˜ ê²°ê³¼ ê²€ì¦
    with open(wav_path, 'rb') as f:
        if f.read(4) != b'RIFF':
            raise RuntimeError(f"ffmpeg ë³€í™˜ í›„ì—ë„ WAVê°€ ì•„ë‹™ë‹ˆë‹¤: {wav_path}")

    return wav_path


def merge_wav_files(input_files, out_path):
    """
    wave ëª¨ë“ˆë¡œ WAV ë³‘í•© (ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ë¸”ë¡ ë‹¨ìœ„ë¡œ ì½ì–´ì„œ ì”€)
    ëª¨ë“  ì…ë ¥ íŒŒì¼ì˜ (channels, sampwidth, framerate, comptype) ë™ì¼í•´ì•¼ í•¨
    """
    if not input_files:
        raise ValueError("ë³‘í•©í•  WAV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")


    print("[merge] input_files:")
    for p in input_files:
        size = os.path.getsize(p) if os.path.exists(p) else -1
        hdr = _peek_header(p, 12)
        print(f"  - {p} (size={size} bytes, header={hdr})")

     # 1) ê¸°ì¤€ íŒŒë¼ë¯¸í„° í™•ë³´ (ì²« íŒŒì¼ ì˜¤í”ˆì—ì„œ ì—ëŸ¬ê°€ ë‚˜ë©´ WAVê°€ ì•„ë‹ ê°€ëŠ¥ì„± í¼)
    try:
        with wave.open(input_files[0], "rb") as w0:
            nchannels = w0.getnchannels()
            sampwidth = w0.getsampwidth()
            framerate = w0.getframerate()
            comptype = w0.getcomptype()
            compname = w0.getcompname()
            print(f"[merge] base params: ch={nchannels}, width={sampwidth}, rate={framerate}, comp={comptype}")
    except wave.Error as we:
        # RIFFê°€ ì•„ë‹Œ ê²½ìš° ëŒ€ë¶€ë¶„ ì—¬ê¸°ì„œ í„°ì§
        raise HTTPException(status_code=415, detail=f"ì²« íŒŒì¼ì´ WAVê°€ ì•„ë‹™ë‹ˆë‹¤: {input_files[0]} ({we})")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì²« íŒŒì¼ ì˜¤í”ˆ ì¤‘ ì˜ˆì™¸: {input_files[0]} ({e})")


    # 2) ì¶œë ¥ íŒŒì¼ ìƒì„±
    try:
        with wave.open(out_path, "wb") as out:
            out.setnchannels(nchannels)
            out.setsampwidth(sampwidth)
            out.setframerate(framerate)
            out.setcomptype(comptype, compname)

            # 3) ìˆœì„œëŒ€ë¡œ ì´ì–´ë¶™ì´ê¸°
            for fpath in input_files:
                # ë¹ ë¥¸ í—¤ë” ì²´í¬
                if not _is_riff(fpath):
                    raise HTTPException(status_code=415, detail=f"RIFF(WAV)ê°€ ì•„ë‹Œ íŒŒì¼: {fpath}")

                try:
                    with wave.open(fpath, "rb") as w:
                        # íŒŒë¼ë¯¸í„° ì¼ì¹˜ ê²€ì‚¬
                        if (w.getnchannels() != nchannels or
                            w.getsampwidth() != sampwidth or
                            w.getframerate() != framerate or
                            w.getcomptype() != comptype):
                            raise HTTPException(
                                status_code=415,
                                detail=(f"ì˜¤ë””ì˜¤ íŒŒë¼ë¯¸í„° ë¶ˆì¼ì¹˜: {os.path.basename(fpath)} "
                                        f"(ch={w.getnchannels()}, width={w.getsampwidth()}, "
                                        f"rate={w.getframerate()}, comp={w.getcomptype()}) "
                                        f"vs ê¸°ì¤€(ch={nchannels}, width={sampwidth}, "
                                        f"rate={framerate}, comp={comptype})")
                            )

                        # ë¸”ë¡ ë‹¨ìœ„ ë³µì‚¬ (frame ë‹¨ìœ„)
                        block_frames = 64 * 1024
                        remaining = w.getnframes()
                        while remaining > 0:
                            chunk = min(remaining, block_frames)
                            data = w.readframes(chunk)
                            out.writeframes(data)
                            remaining -= chunk
                except wave.Error as we:
                    # íŠ¹ì • íŒŒì¼ì—ì„œë§Œ WAV íŒŒì‹± ì˜¤ë¥˜
                    raise HTTPException(status_code=415, detail=f"WAV íŒŒì‹± ì‹¤íŒ¨: {fpath} ({we})")
                except HTTPException:
                    # ìœ„ì—ì„œ ìƒíƒœì½”ë“œ ì •í•´ ì˜¬ë¦° ê²½ìš° ê·¸ëŒ€ë¡œ ë˜ì§
                    raise
                except Exception as e:
                    traceback.print_exc()
                    raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸: {fpath} ({e})")
    except HTTPException:
        raise
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ì¶œë ¥ íŒŒì¼ ì‘ì„± ì¤‘ ì˜ˆì™¸: {out_path} ({e})")


    return out_path


def _normalize_base_url(url: str) -> str:
    """
    .envì—ëŠ” baseë§Œ ìˆì–´ë„ ë˜ê³ , ë§Œì•½ /recognizer, /recognizer/url, /recognizer/uploadê°€ ë¶™ì–´ìˆìœ¼ë©´ ë–¼ì–´ë‚¸ë‹¤.
    """
    if not url:
        raise HTTPException(status_code=500, detail="CLOVA_INVOKE_URL ì´ ë¹„ì—ˆìŠµë‹ˆë‹¤.")
    url = url.strip().rstrip("/")
    for suf in ("/recognizer/upload", "/recognizer/url", "/recognizer"):
        if url.endswith(suf):
            url = url[: -len(suf)]
            break
    return url


def Start_STT(out_path: str, class_id: str) -> dict:
    print(f"â–¶ï¸ [STT] ì‹œì‘: {out_path} (class_id={class_id})")

    # ../backend/.env ë¡œë“œ
    env_path = os.path.join(os.path.dirname(__file__), "../backend/.env")
    print(f"ğŸ§© env ê²½ë¡œ: {env_path} exists= {os.path.exists(env_path)}")
    load_dotenv(env_path)

    raw_url = os.getenv("CLOVA_INVOKE_URL", "")
    secret  = os.getenv("CLOVA_SECRET_KEY", "")

    # BASE URL ì •ê·œí™” â†’ /recognizer/upload ë¶™ì—¬ ì‚¬ìš©
    try:
        base_url = _normalize_base_url(raw_url)
    except HTTPException as he:
        return {"ok": False, "detail": he.detail}

    endpoint = base_url + "/recognizer/upload"
    print("ğŸŒ BASE_URL:", base_url)
    print("ğŸ”š ENDPOINT:", endpoint)
    print("ğŸ”‘ SECRET_KEY head:", (secret[:6] + "â€¦") if secret else "None")
    print("ğŸŒ BASE_URL raw repr:", repr(base_url))
    try:
        part = base_url.split("/external/v1/")[1]
        app_id, domain_id = part.split("/")[0], part.split("/")[1]
        print(f"ğŸ” app_id={app_id}, domain_id={domain_id}")
    except Exception:
        pass

    if not secret:
        return {"ok": False, "detail": "CLOVA_SECRET_KEY ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."}
    if not os.path.isfile(out_path):
        return {"ok": False, "detail": f"íŒŒì¼ ì—†ìŒ: {out_path}"}

    # íŒŒì¼ í—¤ë”/í¬ê¸° ë¡œê·¸
    hdr12 = _peek_header(out_path, 12)
    size = os.path.getsize(out_path)
    print(f"ğŸ“¦ ì—…ë¡œë“œ íŒŒì¼ í¬ê¸°: {size} bytes, í—¤ë”: {hdr12!r}")

    # A ë°©ë²•: í™”ì ì¸ì‹/ì›Œë“œ ì–¼ë¼ì¸ë¨¼íŠ¸ OFF
    request_body = {
        "language": "ko-KR",
        "completion": "sync",
        "callback": None,
        "userdata": None,
        "wordAlignment": False,           # OFF
        "fullText": True,
        "forbiddens": None,
        "boostings": None,
        "diarization": {"enable": False}, # OFF
        "sed": None,
    }

    headers = {
        "Accept": "application/json;UTF-8",
        "X-CLOVASPEECH-API-KEY": secret,
    }

    # ì¬í˜„ìš© curl
    safe_path = out_path.replace("\\", "/")
    print("ğŸš curl ì˜ˆì‹œ:")
    print(
        'curl -X POST "{url}" '
        '-H "X-CLOVASPEECH-API-KEY: {key}" '
        '-H "Accept: application/json;UTF-8" '
        '-F "media=@{path}" '
        '-F "params={params};type=application/json"'
        .format(url=endpoint, key=(secret[:6] + "â€¦"),
                path=safe_path, params=json.dumps(request_body, ensure_ascii=False))
    )

    started = time.time()
    try:
        with open(out_path, "rb") as f:
            files = {
                # ê³µì‹ ì˜ˆì œì™€ ë™ì¼: íŒŒì¼ í•¸ë“¤ì„ ê·¸ëŒ€ë¡œ ì „ë‹¬
                "media": f,
                "params": (None, json.dumps(request_body, ensure_ascii=False).encode("UTF-8"), "application/json"),
            }
            resp = requests.post(endpoint, headers=headers, files=files, timeout=600)
    except requests.Timeout as e:
        print("â±ï¸ íƒ€ì„ì•„ì›ƒ:", e)
        return {"ok": False, "detail": f"ìš”ì²­ íƒ€ì„ì•„ì›ƒ: {e}"}
    except Exception as e:
        print("âš ï¸ ìš”ì²­ ì˜ˆì™¸:", e)
        return {"ok": False, "detail": f"ìš”ì²­ ì‹¤íŒ¨: {e}"}

    took = time.time() - started
    ctype = resp.headers.get("content-type", "")
    print(f"âœ… ì‘ë‹µ: status={resp.status_code}, content-type={ctype}, took={took:.2f}s")
    try:
        print("ğŸ” resp headers:", dict(resp.headers))
    except Exception:
        pass
    preview = (resp.text or "")[:300].replace("\n", " ")
    print("ğŸ“ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°:", preview)

    # ì‘ë‹µ ë¤í”„
    transcript_dir = os.path.dirname(out_path)
    debug_path = os.path.join(transcript_dir, "stt_response_debug.txt")
    try:
        with open(debug_path, "w", encoding="utf-8") as fw:
            fw.write(f"HTTP {resp.status_code}\nContent-Type: {ctype}\nTook: {took:.2f}s\n\n")
            fw.write(resp.text or "")
        print("ğŸ’¾ ì‘ë‹µ ë¤í”„:", debug_path)
    except Exception as e:
        print("âš ï¸ ì‘ë‹µ ë¤í”„ ì €ì¥ ì‹¤íŒ¨:", e)

    # ì—ëŸ¬ ì²˜ë¦¬ (ë©”ì‹œì§€ ë³´ê°•)
    if resp.status_code == 404:
        hint = "404=ê²½ë¡œ ë¯¸ë§¤í•‘. ê°™ì€ ë„ë©”ì¸ì˜ Invoke URL/Secret Keyì¸ì§€, URL ë ê²½ë¡œ(/recognizer/upload) í™•ì¸."
        return {"ok": False, "detail": f"HTTP 404: {resp.text} | HINT: {hint}"}
    if resp.status_code in (401, 403):
        return {"ok": False, "detail": "í‚¤/ê¶Œí•œ ì˜¤ë¥˜. Secret Key/ë„ë©”ì¸ ì§ì„ í™•ì¸í•˜ì„¸ìš”."}
    if resp.status_code == 415:
        return {"ok": False, "detail": "ì „ì†¡ í˜•ì‹ ì˜¤ë¥˜. multipart(media/params) êµ¬ì„± í™•ì¸."}
    if resp.status_code == 400:
        return {"ok": False, "detail": f"ìš”ì²­ íŒŒë¼ë¯¸í„° ì˜¤ë¥˜: {resp.text}"}  # (ì´ì „ 'speaker detect is off' ê°™ì€ ì¼€ì´ìŠ¤)
    if resp.status_code != 200:
        return {"ok": False, "detail": f"HTTP {resp.status_code}: {resp.text}"}

    # ê²°ê³¼ ì €ì¥
    try:
        data = resp.json()
        text = data.get("text") or data.get("result") or json.dumps(data, ensure_ascii=False)
    except Exception:
        text = resp.text
    text = (text or "").strip()

    transcript_path = os.path.join(transcript_dir, "transcript.txt")
    try:
        with open(transcript_path, "w", encoding="utf-8") as fw:
            fw.write(text)
        print("âœ… transcript ì €ì¥:", transcript_path)
    except Exception as e:
        print("âš ï¸ transcript ì €ì¥ ì‹¤íŒ¨:", e)
        return {"ok": True, "text": text, "detail": f"ì €ì¥ ì‹¤íŒ¨: {e}"}

    return {"ok": True, "text": text, "transcript_path": transcript_path}



def _load_openai_clients():
    # ../backend/.env ë¡œë“œ
    env_path = os.path.join(os.path.dirname(__file__), "../backend/.env")
    if os.path.exists(env_path):
        load_dotenv(env_path)
    print("env_path in _load_openai_clients:", env_path)

    use_gms_openai = os.getenv("USE_GMS_OPENAI", "false").lower() == "true"
    openai_key = os.getenv("OPENAI_API_KEY", "").strip()

    if use_gms_openai:
        gms_key = os.getenv("GMS_KEY", "").strip()
        gms_openai_base = os.getenv("GMS_OPENAI_BASE", "").strip().rstrip("/")
        if not gms_key or not gms_openai_base:
            raise RuntimeError("USE_GMS_OPENAI=true ì¸ë° GMS_KEY ë˜ëŠ” GMS_OPENAI_BASE ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        # GMS í”„ë¡ì‹œ ê²½ìœ  (ì¤‘ìš”: /v1 ë¶™ì´ê¸°)
        client = OpenAI(api_key=gms_key, base_url=gms_openai_base + "/v1")
    else:
        if not openai_key:
            raise RuntimeError("OPENAI_API_KEY ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        client = OpenAI(api_key=openai_key)

    clean_model   = os.getenv("OPENAI_CLEAN_MODEL",   "gpt-4o-mini")
    summary_model = os.getenv("OPENAI_SUMMARY_MODEL", "gpt-4o-mini")
    return client, clean_model, summary_model


def summarize_text_auto(transcript_path: str, out_dir: str) -> dict:
   
    try:
        oai, clean_model, summary_model = _load_openai_clients()
        env_path = os.path.normpath(os.path.join(os.path.dirname(__file__), "../backend/.env"))
        if os.path.exists(env_path):
            load_dotenv(env_path)

        use_claude = os.getenv("USE_GMS_CLAUDE", "false").lower() == "true"
        gms_key    = os.getenv("GMS_KEY", "").strip()
        
        gms_base = os.getenv("GMS_ANTHROPIC_BASE", "https://gms.ssafy.io/gmsapi/api.anthropic.com").rstrip("/")
        
        if not os.path.isfile(transcript_path):
            return {"ok": False, "detail": f"transcript ì—†ìŒ: {transcript_path}"}

        with open(transcript_path, "r", encoding="utf-8") as f:
            raw = f.read()

        def chunk_text(text: str, max_chars: int):
            chunks, buf = [], []
            for line in text.splitlines(keepends=True):
                if sum(len(x) for x in buf) + len(line) > max_chars and buf:
                    chunks.append("".join(buf)); buf = []
                buf.append(line)
            if buf: chunks.append("".join(buf))
            return chunks

        def pick_local_font() -> str | None:
            # 0) ENVê°€ ìµœìš°ì„ 
            font_env = os.getenv("PDF_FONT_PATH", "").strip()
            if font_env and os.path.exists(font_env):
                return font_env

            # 1) FastAPIProject/fonts (main.pyì™€ ê°™ì€ í´ë”)
            candidates = [
                os.path.join(HERE, "fonts"),
                os.path.normpath(os.path.join(HERE, "..", "backend", "fonts")),  # ë°±ì—”ë“œ ìª½ë„ fallback
            ]
            for d in candidates:
                if not os.path.isdir(d):
                    continue
                # ìš°ì„ ìˆœìœ„ë¡œ NotoSansKR-Regular ìš°ì„ 
                for name in ("NotoSansKR-Regular.ttf", "NotoSansKR-Regular.otf"):
                    p = os.path.join(d, name)
                    if os.path.exists(p):
                        return p
                # ì•„ë¬´ ttf/otf í•˜ë‚˜ë¼ë„
                for fn in os.listdir(d):
                    if fn.lower().endswith((".ttf", ".otf")):
                        return os.path.join(d, fn)
            return None

        def markdown_to_pdf(md_text: str, pdf_path: str):
            font_path = pick_local_font()
            pdf = FPDF(format="A4", unit="mm")
            pdf.set_auto_page_break(auto=True, margin=15)
            pdf.add_page()
            if font_path and os.path.exists(font_path):
                pdf.add_font("KR", "", font_path, uni=True)
                pdf.add_font("KR-B", "", font_path, uni=True)
                pdf.add_font("KR-Mono", "", font_path, uni=True)
                base, bold, mono = "KR", "KR-B", "KR-Mono"
                pdf.set_font(base, size=12)
            else:
                base, bold, mono = "Arial", "Arial", "Courier"  # í•œê¸€ ê¹¨ì§ˆ ìˆ˜ ìˆìŒ
                pdf.set_font(base, size=12)
            in_code = False
            for raw_line in md_text.splitlines():
                line = raw_line.rstrip("\n")
                if line.strip().startswith("```"):
                    in_code = not in_code
                    pdf.set_font(mono if in_code else base, size=10 if in_code else 12)
                    continue
                if in_code:
                    pdf.multi_cell(0, 6, txt=line); continue
                if line.startswith("### "):
                    pdf.set_font(bold, size=12); pdf.multi_cell(0,7,line[4:].strip()); pdf.set_font(base,12); pdf.ln(1); continue
                if line.startswith("## "):
                    pdf.set_font(bold, size=14); pdf.multi_cell(0,8,line[3:].strip()); pdf.set_font(base,12); pdf.ln(1); continue
                if line.startswith("# "):
                    pdf.set_font(bold, size=16); pdf.multi_cell(0,9,line[2:].strip()); pdf.set_font(base,12); pdf.ln(1); continue
                if line.strip().startswith("- "):
                    pdf.multi_cell(0,6,"â€¢ "+line.strip()[2:]); continue
                if not line.strip():
                    pdf.ln(1); continue
                pdf.multi_cell(0,6,line)
            pdf.output(pdf_path)

        # 1) ì „ì²˜ë¦¬(clean) â€” OpenAI
        system_clean = (
            "ë„ˆëŠ” í•œêµ­ì–´ ì „ì‚¬ í…ìŠ¤íŠ¸ë¥¼ ì •ì œí•˜ëŠ” ë„ìš°ë¯¸ë‹¤. "
            "ì›ë¬¸ ì˜ë¯¸ë¥¼ ë³´ì¡´í•˜ê³  í™˜ê°ì„ í”¼í•œë‹¤. "
            "í•´ì•¼ í•  ì¼: ë¬¸ì¥ ê²½ê³„/ë¬¸ì¥ë¶€í˜¸ ë³µì›, ë„ì–´ì“°ê¸°Â·ë§ì¶¤ë²• ë³´ì •, ì¤‘ë³µ/ì¡ìŒ ìµœì†Œí™”. "
            "ë¶ˆëª…í™•í•˜ë©´ [ë¶ˆëª…í™•]ë¡œ í‘œê¸°í•˜ê³  ì„ì˜ë¡œ ë³´ì¶©í•˜ì§€ ì•ŠëŠ”ë‹¤."
        )
        o3_max = int(os.getenv("O3_CHUNK_CHARS", "9000"))
        clean_chunks = []
        for i, ch in enumerate(chunk_text(raw, o3_max), 1):
            prompt = (
                "ì•„ë˜ í•œêµ­ì–´ í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ ì™œê³¡ ì—†ì´ ì •ë¦¬í•˜ì„¸ìš”.\n"
                "- ë¬¸ì¥ë¶€í˜¸/ë¬¸ì¥ ê²½ê³„ ë³µì›, ë„ì–´ì“°ê¸°/ë§ì¶¤ë²• ë³´ì •\n"
                "- ëª…ë°±í•œ ì¤‘ë³µ/ì¡ìŒì€ ê°„ë‹¨íˆ ì •ë¦¬(ì‚¬ì‹¤ ì¶”ê°€/ì‚­ì œ ê¸ˆì§€)\n"
                "- ê³ ìœ ëª…ì‚¬ê°€ í•œêµ­ì–´ ìŒì—­ì¼ ë•Œ, ë§¥ë½ì´ ëª…í™•í•˜ë©´ ì›ì–´(ì˜ˆ: C++)ë¡œ ë³µì›\n"
                "- ë¶ˆëª…í™•í•˜ë©´ [ë¶ˆëª…í™•] í‘œê¸°\n\n"
                f"{ch}"

            )
            try:
                resp = oai.responses.create(
                    model=clean_model,
                    input=[
                        {"role":"system","content": system_clean},
                        {"role":"user","content": prompt}
                    ],
                    temperature=0.2,
                    max_output_tokens=2000,
                )
                clean_chunks.append(resp.output_text.strip())
            except Exception:
                comp = oai.chat.completions.create(
                    model=clean_model,
                    messages=[
                        {"role":"system","content": system_clean},
                        {"role":"user","content": prompt}
                    ],
                    temperature=0.2,
                )
                clean_chunks.append(comp.choices[0].message.content.strip())
        cleaned = "\n\n".join(clean_chunks)
        cleaned_path = os.path.join(out_dir, "cleaned.txt")
        with open(cleaned_path, "w", encoding="utf-8") as fw:
            fw.write(cleaned)

        # 2) ë§µ ìš”ì•½ â€” OpenAI
        system_summarize = (
            
            
            "ë„ˆëŠ” ì •í™•í•œ í•œêµ­ì–´ í•„ê¸°ìë‹¤. í™˜ê° ì—†ì´ í•µì‹¬ì„ êµ¬ì¡°í™”í•˜ê³ , "
            "ìˆ˜ì‹ì€ ì…ë ¥ì— ì‹¤ì œ ì–¸ê¸‰ëœ ê²½ìš°ì—ë§Œ ```math ë¸”ë¡ì„ ì‚¬ìš©í•œë‹¤."
        )
        sum_max = int(os.getenv("OAI_SUMMARY_CHARS", "8000"))
        map_notes = []
        for i, ch in enumerate(chunk_text(cleaned, sum_max), 1):
            prompt = (
                 "ì•„ë˜ í…ìŠ¤íŠ¸ë¥¼ í•œêµ­ì–´ ê°•ì˜ ë…¸íŠ¸ë¡œ ìš”ì•½í•˜ì„¸ìš”.\n"
                "- í•µì‹¬ í¬ì¸íŠ¸ 3~6ê°œ ë¶ˆë¦¿\n"
                "- ìˆ˜í•™/ê³¼í•™/ê³µí•™ ë“±ì—ì„œ ì‹¤ì œ ì–¸ê¸‰ëœ ê³µì‹ì´ ìˆìœ¼ë©´ ```math ë¸”ë¡ìœ¼ë¡œ í‘œê¸°\n"
                "- ì…ë ¥ì— ì—†ëŠ” ì‚¬ì‹¤ ê¸ˆì§€, ë¶ˆëª…í™•í•˜ë©´ [ë¶ˆëª…í™•]\n\n"
                f"{ch}"
            )
            try:
                resp = oai.responses.create(
                    model=summary_model,
                    input=[
                        {"role":"system","content": system_summarize},
                        {"role":"user","content": prompt}
                    ],
                    temperature=0.3,
                    max_output_tokens=2200,
                )
                map_notes.append(resp.output_text.strip())
            except Exception:
                comp = oai.chat.completions.create(
                    model=summary_model,
                    messages=[
                        {"role":"system","content": system_summarize},
                        {"role":"user","content": prompt}
                    ],
                    temperature=0.3,
                )
                map_notes.append(comp.choices[0].message.content.strip())

        notes_joined = "\n\n---\n\n".join(map_notes)

        # 3) ìµœì¢… ë¦¬ë“€ìŠ¤ â€” Claude via GMS (ìš°ì„ )
        final_md = None
        if use_claude and gms_key:
            url = f"{gms_base}/v1/messages"
            headers = {
                "Content-Type": "application/json",
                "x-api-key": gms_key,
                "anthropic-version": "2023-06-01",
            }
            payload = {
                "model": "claude-3-7-sonnet-latest",
                "max_tokens": 4500,
                "system": "ë„ˆëŠ” í•œêµ­ì–´ ê¸°ìˆ  ë¬¸ì„œ ì‘ì„±ìë‹¤. ë¶€ë¶„ ìš”ì•½ë“¤ì„ í•˜ë‚˜ì˜ ì¼ê´€ëœ ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œë¡œ í†µí•©í•˜ë¼. ì¤‘ë³µ ì œê±°, ìš©ì–´/í‘œê¸° í†µì¼, ì‚¬ì‹¤ ë³´ì¡´, í™˜ê° ê¸ˆì§€.",
                "messages": [
                    {"role": "user", "content":
                        "ë‹¤ìŒ 'ë¶€ë¶„ ìš”ì•½ ë…¸íŠ¸'ë¥¼ í†µí•©í•´ í•˜ë‚˜ì˜ ê°•ì˜ ë¬¸ì„œë¥¼ ë§Œë“¤ì–´ë¼.\n"
                        "- ì„¹ì…˜: # ìš”ì•½(5~8ë¬¸ì¥), ## í•µì‹¬ ê°œë…(ë¶ˆë¦¿ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸), ## ìˆ˜ì‹/ì •ì˜(ìˆ˜í•™/ê³¼í•™ ë“± ìˆ˜ì‹ì´ ìˆëŠ” ê²½ìš°ë§Œ, ```math)\n"
                        "- ì¤‘ë³µ ì œê±°, ìš©ì–´ ì¼ê´€ì„± ìœ ì§€, ì‚¬ì‹¤ ì¶”ê°€/ì‚­ì œ ê¸ˆì§€\n\n"
                        f"{notes_joined}"
                    }
                ],
            }
            r = requests.post(url, headers=headers, data=json.dumps(payload), timeout=120)
            if r.status_code == 200:
                j = r.json()
                content = j.get("content", [])
                if content and isinstance(content, list) and isinstance(content[0], dict) and "text" in content[0]:
                    final_md = content[0]["text"].strip()
            else:
                print("[GMS Claude] HTTP", r.status_code, r.text[:200])

        # í´ë°± â€” OpenAI reduce
        if not final_md:
            prompt = (
                "ë‹¤ìŒ ìš”ì•½ ë…¸íŠ¸ ë¬¶ìŒì„ í•˜ë‚˜ì˜ ë¬¸ì„œë¡œ í†µí•©í•˜ì„¸ìš”. "
                "ì¤‘ë³µ ì œê±°, ìš©ì–´ ì¼ê´€ì„± ìœ ì§€, ì‚¬ì‹¤ì¶”ê°€ ê¸ˆì§€. "
                "ì¶œë ¥ì€ Markdownìœ¼ë¡œ í•˜ê³  ì•„ë˜ ì„¹ì…˜ì„ í¬í•¨:\n"
                "1) ìš”ì•½(5~8ë¬¸ì¥)\n"
                "2) í•µì‹¬ ê°œë… ë¦¬ìŠ¤íŠ¸\n"
                "3) ìˆ˜í•™, ê³¼í•™, ê³µí•™ê³¼ ê°™ì´ ê³µì‹ì´ í•„ìš”, ì–¸ê¸‰ ë˜ê±°ë‚˜ ê³µì‹ì´ ìˆìœ¼ë©´ ì„¤ëª…ì´ ì˜ ëœë‹¤ë©´ ìˆ˜ì‹ì„ í‘œê¸°í•´ì¤˜\n"
                f"{notes_joined}"
            )
            try:
                resp = oai.responses.create(
                    model=summary_model,
                    input=[
                        {"role":"system","content":
                         """
                        ë‚´ê°€ í•œêµ­ì–´ë¡œ ì‘ì„±ëœ ë°©ëŒ€í•œ í…ìŠ¤íŠ¸ë¥¼ ë„ˆì—ê²Œ ì¤„ê²Œ. 
                        í…ìŠ¤íŠ¸ ë‚´ìš©ì€ ì„ ìƒë‹˜ì´ í•™ìƒë“¤ì—ê²Œ ê°€ë¥´ì¹œ ë‚´ìš©, ì¦‰ ìˆ˜ì—… ë‚´ìš©ì´ì•¼. 
                        ë”°ë¼ì„œ í…ìŠ¤íŠ¸ëŠ” ìˆ˜í•™, ì–¸ì–´, ê³¼í•™, ì—­ì‚¬, ê²½ì œ, ê³µí•™ ë“± ì´ˆ,ì¤‘,ê³ , ëŒ€í•™êµë¥¼ í¬í•¨í•´ ì£¼ì‹, ë¶€ë™ì‚° ë“± ë‹¤ì–‘í•œ ë‚´ìš©ì¼ ìˆ˜ ìˆì–´. 
                        í…ìŠ¤íŠ¸ëŠ” ì •ë§ ë§ì€ ë‹¨ì–´ë¥¼ í¬í•¨í•˜ê³  ìˆê¸° ë•Œë¬¸ì— ë‚˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì˜ ìš”ì•½í•´ì„œ í•™ìƒë“¤ì—ê²Œ ì£¼ê³  ì‹¶ì–´. 
                        ë”°ë¼ì„œ í…ìŠ¤íŠ¸ì— ìˆëŠ” ìˆ˜ì—… ë‚´ìš©ë§Œì„ í¬í•¨í•˜ê³ , hallucinationsë¥¼ í”¼í•˜ê³ , í•œêµ­ì–´ ê¹”ë”í•œ í•œêµ­ì–´ Markdownì„ ì‘ì„±í•´ì¤˜. 
                        """},
                        {"role":"user","content":prompt}
                    ],
                    temperature=0.3,
                    max_output_tokens=3000,
                )
                final_md = resp.output_text.strip()
            except Exception:
                comp = oai.chat.completions.create(
                    model=summary_model,
                    messages=[
                        {"role":"system","content":"You are a senior Korean technical writer. Merge partial notes into one coherent Markdown document."},
                        {"role":"user","content":prompt}
                    ],
                    temperature=0.3,
                )
                final_md = comp.choices[0].message.content.strip()

        # 4) ì €ì¥ & PDF
        summary_md_path  = os.path.join(out_dir, "summary.md")
        summary_pdf_path = os.path.join(out_dir, "summary.pdf")
        with open(summary_md_path, "w", encoding="utf-8") as fw:
            fw.write(final_md)

        try:
            markdown_to_pdf(final_md, summary_pdf_path)
        except Exception as pdf_err:
            # í°íŠ¸ ë“±ìœ¼ë¡œ ì‹¤íŒ¨í•´ë„ PDF íŒŒì¼ì€ ë§Œë“ ë‹¤(ë‚´ìš©ì´ ì¼ë¶€ ê¹¨ì§ˆ ìˆ˜ ìˆìŒ)
            print(f"[PDF] markdown_to_pdf ì‹¤íŒ¨, fallback ì‹¤í–‰: {pdf_err}")
            pdf = FPDF(format="A4", unit="mm")
            pdf.set_auto_page_break(auto=True, margin=15)
            pdf.add_page()
            pdf.set_font("Arial", size=12)
            for line in final_md.splitlines():
                pdf.multi_cell(0, 6, line)
            pdf.output(summary_pdf_path)

        print("âœ… summary ì €ì¥:", summary_md_path, " / ", summary_pdf_path)

        return {
            "ok": True,
            "summary_path": summary_md_path,
            "summary_pdf_path": summary_pdf_path,
            "clean_path": cleaned_path,
        }

    except Exception as e:
        traceback.print_exc()
        return {"ok": False, "detail": f"summarize_text_auto ì‹¤íŒ¨: {e}"}


def send_summary_to_api(class_id: str, md_path: str | None, pdf_path: str | None) -> dict:
    
    try:
        env_path = os.path.join(os.path.dirname(__file__), "../backend/.env")
        if os.path.exists(env_path):
            load_dotenv(env_path)

        url = os.getenv("SUMMARY_UPLOAD_URL", "").strip()
        api_key = os.getenv("SUMMARY_UPLOAD_API_KEY", "").strip()
        if not url:
            return {"ok": False, "detail": "SUMMARY_UPLOAD_URL ë¯¸ì„¤ì •"}

        headers = {"Accept": "application/json"}
        if api_key:
            headers["Authorization"] = f"Bearer {api_key}"

        files = {}
        if md_path and os.path.isfile(md_path):
            files["summary_md"] = ("summary.md", open(md_path, "rb"), "text/markdown; charset=utf-8")
        if pdf_path and os.path.isfile(pdf_path):
            files["summary_pdf"] = ("summary.pdf", open(pdf_path, "rb"), "application/pdf")

        if not files:
            return {"ok": False, "detail": "ì „ì†¡í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.(md/pdf ì—†ìŒ)"}

        data = {"class_id": str(class_id)}
        resp = requests.post(url, headers=headers, data=data, files=files, timeout=60)

        # íŒŒì¼ í•¸ë“¤ ë‹«ê¸°
        for f in files.values():
            try: f[1].close()
            except: pass

        if 200 <= resp.status_code < 300:
            return {"ok": True, "status": resp.status_code, "text": (resp.text or "")[:200]}
        return {"ok": False, "status": resp.status_code, "text": (resp.text or "")[:200]}

    except Exception as e:
        return {"ok": False, "detail": f"ì—…ë¡œë“œ ì‹¤íŒ¨: {e}"}

def cleanup_class_dir(class_dir: str) -> dict:
    try:
        if not os.path.isdir(class_dir):
            return {"ok": False, "detail": f"ë””ë ‰í† ë¦¬ ì—†ìŒ: {class_dir}"}

        base = os.path.realpath(MERGE_OUT_DIR)
        target = os.path.realpath(class_dir)

        if os.path.dirname(target) != base:
            return {"ok": False, "detail": f"í—ˆìš© ê²½ë¡œ ì•„ë‹˜: {target} (base={base})"}

        shutil.rmtree(target)
        return {"ok": True, "deleted_dir": target}
    except Exception as e:
        return {"ok": False, "detail": f"ë””ë ‰í† ë¦¬ ì‚­ì œ ì‹¤íŒ¨: {e}"}

def send_summary_to_api(class_id: str, md_path: str | None, pdf_path: str | None) -> dict:

    try:
        env_path = os.path.join(os.path.dirname(__file__), "../backend/.env")
        if os.path.exists(env_path):
            load_dotenv(env_path)

        url_tpl = os.getenv("SUMMARY_UPLOAD_URL", "").strip()
        api_key = os.getenv("SUMMARY_UPLOAD_API_KEY", "").strip()
        if not url_tpl:
            return {"ok": False, "detail": "SUMMARY_UPLOAD_URL ë¯¸ì„¤ì •"}

        # ğŸ”¹ {class_id}/{classId} í…œí”Œë¦¿ ì¹˜í™˜
        url = (url_tpl
               .replace("{class_id}", str(class_id))
               .replace("{classId}", str(class_id)))

        headers = {"Accept": "application/json"}
        if api_key:
            headers["Authorization"] = f"Bearer {api_key}"  # í•„ìš” ì—†ìœ¼ë©´ .envì—ì„œ KEY ë¹„ì›Œë‘ë©´ ë¨

        files = {}
        if md_path and os.path.isfile(md_path):
            files["summary_md"] = ("summary.md", open(md_path, "rb"), "text/markdown; charset=utf-8")
        if pdf_path and os.path.isfile(pdf_path):
            files["summary_pdf"] = ("summary.pdf", open(pdf_path, "rb"), "application/pdf")

        if not files:
            return {"ok": False, "detail": "ì „ì†¡í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.(md/pdf ì—†ìŒ)"}

        data = {"class_id": str(class_id)}
        resp = requests.post(url, headers=headers, data=data, files=files, timeout=60)

        # íŒŒì¼ í•¸ë“¤ ë‹«ê¸°
        for f in files.values():
            try: f[1].close()
            except: pass

        if 200 <= resp.status_code < 300:
            return {"ok": True, "status": resp.status_code, "text": (resp.text or "")[:200]}
        return {"ok": False, "status": resp.status_code, "text": (resp.text or "")[:200]}

    except Exception as e:
        return {"ok": False, "detail": f"ì—…ë¡œë“œ ì‹¤íŒ¨: {e}"}


@app.post("/STT/{class_id}")
def merge_audio(class_id: str):
    print("íŒŒì´ì¬ merge í•©ë³‘ ì²˜ë¦¬ -> class_id : ", class_id)
    """
    ì…ë ¥:  BASE_AUDIO_DIR/{class_id}/audio_*.wav (ì—†ìœ¼ë©´ *.wav)
    ì¶œë ¥:  MERGE_OUT_DIR/Merge__{class_id}.wav
    """
    in_dir = os.path.join(BASE_AUDIO_DIR, str(class_id))
    print("in_dir : ", in_dir)
    if not os.path.isdir(in_dir):
        raise HTTPException(status_code=400, detail=f"Directory not found: {in_dir}")



    # ëŒ€ìƒ íŒŒì¼ ìˆ˜ì§‘
    patterns = [os.path.join(in_dir, "audio_*.wav"), os.path.join(in_dir, "*.wav")]
    candidates = []
    for pat in patterns:
        candidates.extend(glob.glob(pat))
    files = sorted(set(candidates), key=_numeric_key)

    if not files:
        raise HTTPException(status_code=404, detail=f"No WAV files found in {in_dir}")

    
    class_out_dir = os.path.join(MERGE_OUT_DIR, str(class_id))
    os.makedirs(class_out_dir, exist_ok=True)
    out_path = os.path.join(class_out_dir, f"Merge__{class_id}.wav")
    print("out_path : ", out_path)

    try:
        wav_ready = [ensure_wav(p) for p in files]
        
        for p in wav_ready:
            size = os.path.getsize(p)
            with open(p, "rb") as f:
                hdr = f.read(12)
            print(f"  - {p} (size={size}, header={hdr})")  # ì—¬ê¸°ì„œëŠ” ê¼­ b'RIFF'ê°€ ì°í˜€ì•¼ í•¨

        #1) ìŒì„± íŒŒì¼ Merge
        merged = merge_wav_files(wav_ready, out_path)
        print("merged => ", merged)
        #2) STT
        stt_result = Start_STT(out_path,class_id)
        # STT ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ë°˜í™˜
        if not stt_result.get("ok"):
            return {
                "status": "stt_failed",
                "message": "STT ì‹¤íŒ¨",
                "class_id": class_id,
                "input_dir": in_dir,
                "files_merged": [os.path.basename(f) for f in files],
                "output_path": merged,
                "stt_ok": False,
                "stt_detail": stt_result.get("detail"),
                "summary_ok": False,
                "summary_path": None,
                "summary_pdf_path": None,
                "clean_path": None,
                "summary_detail": "STT ì‹¤íŒ¨ë¡œ ìš”ì•½ ë¯¸ìˆ˜í–‰",
            }

         # 3) STT ì„±ê³µ â†’ ìš”ì•½ ì‹¤í–‰
        transcript_path = stt_result.get("transcript_path")
        if not transcript_path:
            return {
                "status": "stt_ok_no_transcript",
                "message": "STTëŠ” ì„±ê³µí–ˆì§€ë§Œ transcript ê²½ë¡œê°€ ì—†ìŠµë‹ˆë‹¤.",
                "class_id": class_id,
                "output_path": merged,
                "stt_ok": True,
                "transcript_path": None,
                "summary_ok": False
            }

        summary_result = summarize_text_auto(transcript_path, os.path.dirname(out_path))
        
        upload_result = None
        cleanup_result = None
        if (summary_result or {}).get("ok"):
            upload_result = send_summary_to_api(
                class_id=class_id,
                md_path=(summary_result or {}).get("summary_path"),
                pdf_path=(summary_result or {}).get("summary_pdf_path"),
            )
            # ì—…ë¡œë“œê°€ ì„±ê³µí–ˆì„ ë•Œë§Œ ë””ë ‰í† ë¦¬ í†µì§¸ ì‚­ì œ
            if upload_result and upload_result.get("ok"):
                class_out_dir = os.path.join(MERGE_OUT_DIR, str(class_id))
                cleanup_result = cleanup_class_dir(class_out_dir)
            else:
                cleanup_result = {"ok": False, "detail": "ì—…ë¡œë“œ ì‹¤íŒ¨ë¡œ ì‚­ì œ ê±´ë„ˆëœ€"}


        
        return {
            "status": "summary_done" if (summary_result or {}).get("ok") else "summary_failed",
            "message": "STT ì„±ê³µ ë° ìš”ì•½ ì²˜ë¦¬ ì™„ë£Œ" if (summary_result or {}).get("ok") else "STT ì„±ê³µ, ìš”ì•½ ì‹¤íŒ¨",
            "class_id": class_id,
            "input_dir": in_dir,
            "files_merged": [os.path.basename(f) for f in files],
            "output_path": merged,
            "stt_ok": True,
            "transcript_path": transcript_path,
            "stt_detail": stt_result.get("detail"),
            "summary_ok": (summary_result or {}).get("ok", False),
            "summary_path": (summary_result or {}).get("summary_path"),
            "summary_pdf_path": (summary_result or {}).get("summary_pdf_path"),
            "clean_path": (summary_result or {}).get("clean_path"),
            "summary_detail": (summary_result or {}).get("detail"),
            "upload_result": upload_result,
            "cleanup_result": cleanup_result,
        }
        

    except ValueError as ve:
        # í¬ë§·/íŒŒë¼ë¯¸í„° ë¬¸ì œ ë“±
        raise HTTPException(status_code=415, detail=str(ve))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Merge failed: {e}")
